{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8cd6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,  # TinyLlama's sweet spot (256-512 tokens)\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b1e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Persist locally (creates ./chroma_db folder)\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"study_notes\",\n",
    "    embedding_function=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"),  # Uses Ollama's model\n",
    "    persist_directory=\"./chroma_db\"  # Critical for later reuse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79bfe447",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.65, \"k\": 4}  # Tune these!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b0c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "llm = OllamaLLM(\n",
    "    model=\"tinyllama\",\n",
    "    temperature=0.3,  # Lower = more factual (critical for study aid)\n",
    "    num_ctx=2048      # TinyLlama's max context window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a35a3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are a STUDY TUTOR analyzing COURSE MATERIALS. \n",
    "Use ONLY the context below to answer. If unsure, say \"I don't know based on my materials\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer concisely in 2-3 sentences:\"\"\"\n",
    "\n",
    "QA_PROMPT = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ede97fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": QA_PROMPT},\n",
    "    return_source_documents=True  # For citations!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31169505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the given context, the question asks for an explanation of backpropagation in neural networks. The answer should be concise and specific to the question asked. In this case, it would be something like \"backpropagation is a technique used in neural networks to update weights based on errors made by the network during training.\"\n",
      "\n",
      "Source Chunks:\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain.invoke(\"Explain backpropagation in neural networks\")\n",
    "print(\"Answer:\", result[\"result\"])\n",
    "print(\"\\nSource Chunks:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"- {doc.metadata['source']} (page {doc.metadata.get('page', 'N/A')})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
